{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport pandas as pd\nfrom skimage import io, transform\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport albumentations as A\nimport cv2\nfrom albumentations.pytorch.transforms import ToTensorV2 as ToTensorV2\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class IITAR13K(Dataset):\n   \n    def __init__(self, csv_file, root_dir, transform=None, target_transform=None):\n       \n        self.boxes = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.boxes)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir,\n                                self.boxes.iloc[idx, 2])\n        img = Image.open(img_name).convert(\"RGB\")\n        \n        if self.transform:\n            img = self.transform(img)\n            \n        label = self.boxes.iloc[idx, 18]\n        bound_boxes = self.boxes.iloc[idx, 14:18]\n        bound_boxes = np.array([bound_boxes])/600\n        bound_boxes = bound_boxes.astype('float').reshape(4)\n        \n        '''if self.target_transform:\n            bound_boxes = self.transform(bound_boxes)\n            label = self.transform(label)'''\n            \n        #sample = {'images': img, 'boxes': bound_boxes, 'labels': label}\n        #target = {'boxes': bound_boxes, 'labels': label}\n        return img, bound_boxes, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transform = transforms.Compose([\n        transforms.Resize((600,600)),\n        \n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = IITAR13K(csv_file=  \"../input/labels-224/ch_graph_obj_train.csv\",\n                                          root_dir= '../input/iit-ar-13k-dataset/training_images/training_images',\n                                           transform=data_transform\n                                          )\ndataset_val = IITAR13K(csv_file= '../input/labels-224/ch_graph_obj_test.csv',\n                                           root_dir= '../input/iit-ar-13k-dataset/test_images/test_images',\n                                           transform=data_transform                                        \n                                          )\n\ndataset_test = IITAR13K(csv_file= '../input/labels-224/ch_graph_obj_val.csv',\n                                           root_dir= '../input/iit-ar-13k-dataset/validation_images/validation_images',\n                                           transform=data_transform) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataset))\nprint(len(dataset_val))\nprint(len(dataset_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BB_model(nn.Module):\n    def __init__(self,fine_tuning=False):\n        super(BB_model, self).__init__()\n        resnet = models.resnet50(pretrained=True)\n        if fine_tuning== True :\n            for param in resnet.parameters():\n                param.requires_grad = False\n        self.features = nn.Sequential(*list(resnet.children())[:-2])\n        #self.features1 = nn.Sequential(*layers[:6])\n        #self.features2 = nn.Sequential(*layers[6:])\n        num_features = 2048\n        self.classifier = nn.Sequential(nn.Linear(num_features, 5))\n        self.bb = nn.Sequential(nn.Dropout(), \n                                nn.Linear(num_features, 1024), nn.ReLU(),\n                                nn.Linear(1024, 512), nn.ReLU(),\n                                nn.Linear(512, 256), nn.ReLU(),\n                                nn.Linear(256, 128), nn.ReLU(),\n                                nn.BatchNorm1d(128), \n                                nn.Dropout(), \n                                nn.Linear(128, 4), nn.Sigmoid())\n        \n    def forward(self, x):\n        x = self.features(x)\n        #x = self.features2(x)\n        x = F.relu(x)\n        x = nn.AdaptiveAvgPool2d((1,1))(x)\n        x = x.view(x.shape[0], -1)\n        return self.bb(x), self.classifier(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bb_iou(boxA, boxB):\n     # determine the (x, y)-coordinates of the intersection rectangle\n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n    # compute the area of intersection rectangle\n    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n    # compute the area of both the prediction and ground-truth\n    # rectangles\n    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n    # compute the intersection over union by taking the intersection\n    # area and dividing it by the sum of prediction + ground-truth\n    # areas - the interesection area\n    iou = interArea / float(boxAArea + boxBArea - interArea)\n    # return the intersection over union value\n    return iou","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pos 0 = TP, pos 1 = FP, pos 2 = FN\ndef metric(out_bb, out_class, y_bb, y_class, batch_size = 4):\n    tresholds = np.arange(0.5, 1, 0.05)\n    res = {str(th): {str(i): np.array([0, 0, 0]) for i in range(5)} for th in tresholds}\n    for i in range(batch_size):\n        \n        IoU = bb_iou(y_bb[i], out_bb[i])\n        for th in tresholds:\n            our_class = str(int(y_class[i]))\n            if IoU >= th:\n                a, b = torch.max(out_class[i], 0)\n                if  b == y_class[i]:\n                    res[str(th)][our_class][0] += 1 # TP\n                else:\n                    res[str(th)][our_class][1] += 1 # FP\n            else:\n                res[str(th)][our_class][2] += 1 # FN\n                \n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, ignore_index: int = -100, gamma: float = 1.0,\n                 reduction: str = 'mean', alpha=None) -> None:\n        super(FocalLoss, self).__init__()\n        self.alpha: float = alpha\n        self.gamma: float = gamma\n        self.reduction: str = reduction\n        self.eps: float = 1e-6\n        self.ce = nn.CrossEntropyLoss(ignore_index=ignore_index, weight=None)\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.nll = nn.NLLLoss(reduce='none')\n\n    def forward(  # type: ignore\n            self,\n            input: torch.Tensor,\n            target: torch.Tensor) -> torch.Tensor:\n\n        # probs = self.softmax(input)\n        probs = F.log_softmax(input, dim=1)\n        p = torch.pow(1 - probs, self.gamma)\n        # focal = self.alpha * p * self.ce(input, target)\n        focal = self.alpha * p * self.nll(F.log_softmax(input, dim=1), target)\n\n        loss_tmp = torch.sum(focal, dim=1)\n\n        if self.reduction == 'none':\n            loss = loss_tmp\n        elif self.reduction == 'mean':\n            loss = torch.mean(loss_tmp)\n        elif self.reduction == 'sum':\n            loss = torch.sum(loss_tmp)\n        else:\n            raise NotImplementedError(\"Invalid reduction mode: {}\".format(self.reduction))\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_metrics(model, valid_dl, epochs, loss_type, floss_a, floss_g, C = 1):\n    model.eval()\n    total = 0\n    sum_loss = 0\n    correct = 0 \n    predit = np.array([])\n    with torch.no_grad():\n        for x, y_bb, y_class, in valid_dl:\n            batch = y_class.shape[0]\n            x = x.to(device)\n            y_class = y_class.to(device)\n            y_bb = y_bb.to(device)\n            out_bb, out_class = model(x)\n            #print(out_bb)\n\n            if loss_type == 'cross':\n                loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n            if loss_type == 'foc':\n                floss=FocalLoss(alpha=floss_a, gamma=floss_g)\n                loss_class = floss.forward(out_class,y_class)\n\n            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n\n            loss_bb = loss_bb.sum()\n            loss = loss_class + loss_bb\n            _, pred = torch.max(out_class, 1)\n            correct += pred.eq(y_class).sum().item()\n            sum_loss += loss.item()\n            total += batch\n    return sum_loss/total, correct/total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_epocs(model, optimizer, train_dl, val_dl, floss_a, floss_g, epochs=40, loss_type='foc'):\n    idx = 0\n    train_losses = []\n    val_losses = []\n    for i in range(epochs):\n        start = time.time()\n        model.train()\n        total = 0\n        sum_loss = 0\n        for x, y_bb, y_class in train_dl:\n\n            batch = y_class.shape[0]\n            x = x.to(device)\n            y_class = y_class.to(device)\n            y_bb = y_bb.to(device)\n            out_bb, out_class, = model(x)\n            #print(out_class.shape)\n            #print(y_class.shape)\n            \n            if loss_type == 'cross':\n                loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n            if loss_type == 'foc':\n                floss=FocalLoss(alpha=floss_a, gamma=floss_g)\n                loss_class = floss.forward(out_class,y_class)\n                \n            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n            loss_bb = loss_bb.sum()\n            loss = loss_class + loss_bb\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            idx += 1\n            total += batch\n            sum_loss += loss.item()\n        train_loss = sum_loss/total\n        val_loss, val_acc = val_metrics(model, val_dl, epochs=i, loss_type = 'foc', floss_a =floss_a, floss_g =floss_g)\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n        print(f'time for one epoch: {time.time()-start}, epoch: {i}')\n    return sum_loss/total, train_losses, val_losses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_epocs_hyper(model, optimizer, train_dl, val_dl, epochs, loss_type, floss_a, floss_g, C = 1):\n    idx = 0\n    epoch_acc = {}\n    for i in range(epochs):\n        start = time.time()\n        model.train()\n        total = 0\n        sum_loss = 0\n        for x, y_bb, y_class in train_dl:\n\n            batch = y_class.shape[0]\n            x = x.to(device)\n            y_class = y_class.to(device)\n            y_bb = y_bb.to(device)\n            out_bb, out_class, = model(x)\n            #print(out_class)\n            \n            if loss_type == 'cross':\n                loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n            if loss_type == \"foc\":\n                floss=FocalLoss(alpha=floss_a, gamma=floss_g)\n                loss_class = floss.forward(out_class,y_class)\n                \n            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n            loss_bb = loss_bb.sum()\n            loss = loss_class + loss_bb\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            idx += 1\n            total += batch\n            sum_loss += loss.item()\n        \n        train_loss = sum_loss/total\n        val_loss, val_acc = val_metrics(model, val_dl, epochs=i, loss_type = loss_type, floss_a = floss_a, floss_g = floss_g)\n        epoch_acc.update({\"epoch_{}\".format(i):val_acc})\n        \n        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n        print(f'time for une epoch: {time.time()-start}, epoch: {i}')\n    return epoch_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloaders = {'val': torch.utils.data.DataLoader(dataset_val, batch_size=4,\n                                             shuffle=False, num_workers=4, drop_last=True),\n              }\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nnum_epochs = 10\n\nnum_batches = [16]\ndloaders = [\"torch.utils.data.DataLoader(dataset, batch_size=\"+str(nb)+\", shuffle=True, num_workers=4, drop_last=True)\" for nb in num_batches]\n\nwdecays = [0]\nlearn_rates =[0.0001,0.001]\nmom = [0.02]\n\nfloss_alpha = [0.6,0.8,0.9]\nfloss_gamma = [1]\n\noptimizers =[\"torch.optim.SGD(parameters, lr=\"+str(i)+\",momentum=\"+str(j)+\",weight_decay =\" + str(w)+ \")\" for i in learn_rates for j in mom for w in wdecays]\n\nloss_types = [\"foc\"]\naccur = {}\ntot_epochs = num_epochs*len(loss_types)*len(optimizers)*len(dloaders)*len(floss_alpha)*len(floss_gamma)\nprint(\"About to tune {} epochs...\".format(tot_epochs))\nfor lt in loss_types:\n    for dl in dloaders:\n        for o in optimizers:\n            for fa in floss_alpha:\n                for fg in floss_gamma:\n                    parameters = filter(lambda p: p.requires_grad, model.parameters())\n                    model = BB_model().to(device)\n                    \n                    params = \"{dl}, {o}, lt = {lt}, fa = {fa}, fg = {fg}\".format(dl = dl,o = o,lt = lt, fa = fa, fg = fg)\n                    print(params)\n                    accur.update({params:train_epocs_hyper(model, eval(o), eval(dl), dataloaders['val'], epochs=num_epochs, loss_type= lt, floss_a =fa, floss_g = fg)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"Running best hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_batch = 16\n\ndataloaders = {'train': torch.utils.data.DataLoader(dataset, batch_size=num_batch,\n                                             shuffle=True, num_workers=4, drop_last=True),\n                'val': torch.utils.data.DataLoader(dataset_val, batch_size=4,\n                                             shuffle=False, num_workers=4, drop_last=True),\n               'test':  torch.utils.data.DataLoader(dataset_test, batch_size=4,\n                                             shuffle=False, num_workers=4, drop_last=True),\n              }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = BB_model().to('cuda')\nparameters = filter(lambda p: p.requires_grad, model.parameters())\noptimizer = torch.optim.SGD(parameters, lr=0.001, momentum= 0.09)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc, train_losses, val_losses = train_epocs(model, optimizer, dataloaders['train'], dataloaders['val'], floss_a=0.6, floss_g=1, epochs=10, loss_type='foc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nx = range(10)\n# plotting the line 1 points \nplt.plot(x, train_losses, label = \"train\")\n# plotting the line 2 points \nplt.plot(x, val_losses, label = \"valid\")\n\nplt.xlabel('epochs')\n# Set the y axis label of the current axis.\nplt.ylabel('loss')\n# Set a title of the current axes.\nplt.title('Loss per each epoch')\n# show a legend on the plot\nplt.legend()\n# Display a figure.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tresholds = np.arange(0.5, 1, 0.05)\nres = {str(th): {str(i): np.array([0, 0, 0]) for i in range(5)} for th in tresholds}\n\nmodel.eval()\nwith torch.no_grad():\n    for x, y_bb, y_class, in dataloaders['test']:\n            batch = y_class.shape[0]\n            x = x.to(device)\n            y_class = y_class.to(device)\n            y_bb = y_bb.to(device)\n            out_bb, out_class = model(x)\n\n            prov_res = metric(out_bb, out_class, y_bb, y_class, batch_size = batch)\n\n            for th in tresholds:\n                for i in range(5):\n                    res[str(th)][str(i)] += prov_res[str(th)][str(i)] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame.from_dict(res)\ndf.columns = ['0.5', '0.55', '0.6', '0.65', '0.70', '0.75', '0.8', '0.85', '0.90', '0.95' ]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.index:\n    for j in df.columns:\n        l = df[j][i]\n        TP = l[0]; FP = l[1]; FN=l[2]\n        if TP + FP == 0:\n            prec = 0\n        else:\n            prec = TP/(TP+FP)\n        \n        if TP + FN == 0:\n            rec = 0\n        else:\n            rec = TP/(TP+FN)\n        \n        df[j][i] = [round(prec, 5), round(rec, 5)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1 = df\nfor i in f1.index:\n    for j in f1.columns:\n        l = f1[j][i]\n        P = l[0]; R = l[1]\n        if P+R == 0:\n            F_mes = 0\n        else:\n            F_mes = 2*((P*R)/(P+R))\n            \n        f1[j][i] = round(F_mes, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1 = f1.rename(columns={'0.5': 'IoU_th=0.5', '0.55': 'IoU_th=0.55','0.6': 'IoU_th=0.6','0.65': 'IoU_th=0.65',\n                        '0.70': 'IoU_th=0.7','0.75': 'IoU_th=0.75','0.8': 'IoU_th=0.8','0.85': 'IoU_th=0.85',\n                        '0.90': 'IoU_th=0.9','0.95': 'IoU_th=0.95'},\n               index={'0': 'natural_image', '1': 'table', '2':'signature', '3': 'figure', '4': 'logo'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class accuracies\nclasses = ['natural_image','table','signature','figure','logo']\nclass_correct = list(0. for i in range(5))\nclass_total = list(0. for i in range(5))\nmodel.eval()\nwith torch.no_grad():\n    for x, y_bb, y_class in dataloaders['test']:\n        x = x.to(device)\n        labels = y_class.to(device)\n        out_bb, out_class, = model(x)\n        _, predicted = torch.max(out_class, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(5):\n    print('Accuracy of ' + classes[i] + ': ' + str(round(class_correct[i] / class_total[i], 5)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}